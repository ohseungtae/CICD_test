name: CI/CD Pipeline
on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8, 3.9, '3.10']

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Cache pip dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/pip
        key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
        restore-keys: |
          ${{ runner.os }}-pip-

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest pytest-cov pytest-mock

    - name: Run tests
      env:
        PYTHONPATH: .
      run: pytest tests/ -v --cov=src --cov-report=xml

    - name: Create necessary directories
      run: |
        mkdir -p data/dataset
        mkdir -p data/models
        mkdir -p data/results

    - name: Set environment variables for CI
      env:
        ENABLE_MLFLOW: false
        CI: true
      run: |
        echo "ENABLE_MLFLOW=false" >> $GITHUB_ENV
        echo "CI=true" >> $GITHUB_ENV

    - name: Lint with flake8
      run: |
        pip install flake8
        # stop the build if there are Python syntax errors or undefined names
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
        # exit-zero treats all errors as warnings. The GitHub editor is 127 chars wide
        flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics
    
    

    - name: Test with pytest
      run: |
        pytest tests/ -v --cov=src --cov-report=xml

    - name: Upload coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: ./coverage.xml
        flags: unittests
        name: codecov-umbrella
        fail_ci_if_error: false

  integration-test:
    runs-on: ubuntu-latest
    needs: test
    if: github.event_name == 'pull_request'

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Create necessary directories
      run: |
        mkdir -p data/dataset
        mkdir -p data/models
        mkdir -p data/results

    - name: Set environment variables for CI
      run: |
        echo "ENABLE_MLFLOW=false" >> $GITHUB_ENV
        echo "CI=true" >> $GITHUB_ENV

    - name: Run integration tests (Mock data)
      run: |
        # Prophet 모델로 간단한 파이프라인 테스트
        python -c "
        import pandas as pd
        import numpy as np
        from datetime import datetime, timedelta
        
        # 테스트 데이터 생성
        dates = pd.date_range(start='2023-01-01', end='2023-12-31', freq='H')
        temps = 15 + 10 * np.sin(2 * np.pi * np.arange(len(dates)) / (24*365)) + np.random.normal(0, 2, len(dates))
        test_data = pd.DataFrame({'time': dates, 'temp': temps})
        test_data.to_csv('data/dataset/test_weather.csv', index=False)
        
        # 데이터 분할
        split_idx = int(len(test_data) * 0.8)
        train_data = test_data[:split_idx]
        test_data_split = test_data[split_idx:]
        
        train_data.to_csv('data/dataset/train_data.csv', index=False)
        test_data_split.to_csv('data/dataset/test_data.csv', index=False)
        
        print('Test data created successfully')
        "

    - name: Test Prophet training
      run: |
        python -c "
        from src.train.train import train_prophet
        import os
        os.environ['ENABLE_MLFLOW'] = 'false'
        
        model_path, run_id = train_prophet('data/dataset/train_data.csv')
        print(f'Model trained successfully: {model_path}')
        print(f'Run ID: {run_id}')
        "

    - name: Test Prophet evaluation
      run: |
        python -c "
        from src.evaluate.evaluate import evaluate_prophet
        import os
        os.environ['ENABLE_MLFLOW'] = 'false'
        
        metrics = evaluate_prophet('data/models/prophet_model.pkl', 'data/dataset/test_data.csv', 'mock_run_id')
        print(f'Evaluation completed: MAE={metrics[\"mae\"]:.2f}, RMSE={metrics[\"rmse\"]:.2f}')
        "

    - name: Test Future prediction
      run: |
        python -c "
        from src.test.test import predict_future
        import pandas as pd
        import joblib
        import os
        os.environ['ENABLE_MLFLOW'] = 'false'
        
        model = joblib.load('data/models/prophet_model.pkl')
        test_data = pd.read_csv('data/dataset/test_data.csv', parse_dates=['time'])
        last_date = test_data['time'].max()
        
        future_csv = predict_future(model, last_date, days=3, save_name='test_forecast.csv')
        print(f'Future prediction completed: {future_csv}')
        "

  deploy:
    runs-on: ubuntu-latest
    needs: [test, integration-test]
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt

    - name: Build package
      run: |
        pip install build
        python -m build

    - name: Create deployment artifact
      run: |
        mkdir -p deployment
        cp -r src deployment/
        cp main.py deployment/
        cp requirements.txt deployment/
        cp config.yaml deployment/ || echo "config.yaml not found, skipping"

    - name: Archive deployment artifacts
      uses: actions/upload-artifact@v3
      with:
        name: deployment-package
        path: deployment/

    - name: Deploy notification
      run: |
        echo "Deployment package created successfully!"
        echo "Artifacts uploaded and ready for deployment."